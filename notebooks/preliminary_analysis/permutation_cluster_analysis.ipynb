{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import sys\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\gautier\\OneDrive - CentraleSupelec\\3A - Master CNN\\Supervised Project\\pipeline project v0\\scripts\")\n",
    "sys.path.append(r\"C:\\Users\\gautier\\OneDrive - CentraleSupelec\\3A - Master CNN\\Supervised Project\\pipeline project v0\\config\")\n",
    "import eeg_preprocessing as preprocessing\n",
    "import eeg_decoding as decoding\n",
    "import vst_config as config\n",
    "\n",
    "from mne.stats import spatio_temporal_cluster_1samp_test\n",
    "from mne.channels import find_ch_adjacency, make_1020_channel_selections\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mne.viz import plot_compare_evokeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_type = \"start_prod\"\n",
    "baseline_duration = 0.8\n",
    "epoch_duration = 4\n",
    "pick_type = \"all_channels\"\n",
    "\n",
    "subject = \"VST_02_X\"\n",
    "\n",
    "low_freq = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_analysis_report_dir  = f'../../reports/cluster_analysis/{epochs_type}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatio Temporal Cluster Analysis on power time courses data over all epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from mne.channels import find_ch_adjacency\n",
    "\n",
    "\n",
    "def compute_and_plot_stca(epochs, report, report_out, p_accept = 0.05, n_perm = 1024):\n",
    "\n",
    "    # Running the spatio temporal cluster analysis\n",
    "    adjacency, _ = find_ch_adjacency(epochs.info, \"eeg\")\n",
    "\n",
    "    # Transposing the data to fit the cluster analysis\n",
    "    epochs_data = epochs.get_data().transpose(0, 2, 1)\n",
    "\n",
    "    # Subtracting the mean beta power over each electrode\n",
    "    epochs_data = np.apply_along_axis(lambda x: x - np.mean(x), 2, epochs_data)\n",
    "    evo = epochs.average()\n",
    "\n",
    "    cluster_stats = spatio_temporal_cluster_1samp_test(epochs_data,\n",
    "                                                        n_permutations=n_perm, \n",
    "                                                        threshold=None, \n",
    "                                                        n_jobs=-1, \n",
    "                                                        adjacency=adjacency)        \n",
    "    T_obs, clusters, p_values, H0 = cluster_stats\n",
    "    if len(clusters) == 0:\n",
    "        print('No significant clusters found for this predictor')\n",
    "        return\n",
    "\n",
    "    print(p_values)\n",
    "    good_cluster_inds = np.where(p_values < p_accept)[0]\n",
    "    print(str(len(good_cluster_inds)) + ' sign. clusters')\n",
    "\n",
    "    p_min = np.min(p_values)\n",
    "\n",
    "    #======================================================\n",
    "    # Display clusters information\n",
    "    \n",
    "    #======================================================\n",
    "    # if no cluster, display the lowest p of n.s. cluster (as sanity check)\n",
    "    #======================================================\n",
    "    if len(good_cluster_inds) == 0:\n",
    "        good_cluster_inds = np.where(p_values < p_min+0.01)[0]\n",
    "        print(str(len(good_cluster_inds)) + ' n.s. cluster min p')\n",
    "\n",
    "    #======================================================\n",
    "    #% loop over clusters, plot and save in report\n",
    "    for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "        \n",
    "        # unpack cluster information, get unique indices\n",
    "        time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "        ch_inds     = np.unique(space_inds)\n",
    "        time_inds   = np.unique(time_inds)\n",
    "    \n",
    "        # get topography for F stat\n",
    "        f_map = T_obs[time_inds, ...].mean(axis=0)\n",
    "    \n",
    "        # get signals at the sensors contributing to the cluster\n",
    "        # sig_times = blah.times[time_inds]\n",
    "        sig_times = evo.times[time_inds]\n",
    "        \n",
    "        # create spatial mask\n",
    "        mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "        mask[ch_inds, :] = True\n",
    "    \n",
    "        # initialize figure\n",
    "        fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    \n",
    "        # plot average test statistic and mark significant sensors\n",
    "        f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs.info, tmin=0)\n",
    "        \n",
    "        f_evoked.plot_topomap(times=0, mask=mask, axes=ax_topo, cmap='Greys',\n",
    "                            show=False,\n",
    "                            colorbar=False, mask_params=dict(markersize=10))\n",
    "        image = ax_topo.images[0]\n",
    "        \n",
    "        # create additional axes\n",
    "        divider = make_axes_locatable(ax_topo)\n",
    "    \n",
    "        # add axes for colorbar\n",
    "        ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(image, cax=ax_colorbar)\n",
    "        ax_topo.set_xlabel(\n",
    "            'Averaged F-map ({:0.3f} - {:0.3f} s)'.format(*sig_times[[0, -1]]))\n",
    "    \n",
    "        # add new axis for time courses and plot time courses\n",
    "        ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "        \n",
    "        title = 'Cluster #{0}, {1} sensor, p min value {2}'.format(i_clu + 1, len(ch_inds), p_min)\n",
    "        \n",
    "        plot_compare_evokeds([evo], ci = True, title=title, \n",
    "                            picks=ch_inds, axes=ax_signals,\n",
    "                            legend = 'upper right', split_legend=True, \n",
    "                            truncate_yaxis='auto')\n",
    "    \n",
    "        # plot temporal cluster extent\n",
    "        ymin, ymax = ax_signals.get_ylim()\n",
    "        ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                                color='grey', alpha=0.3)\n",
    "    \n",
    "        # clean up viz\n",
    "        fig.subplots_adjust(bottom=.05)\n",
    "\n",
    "        report.add_figure(fig, title=('sign cluster_' + str(p_min)))\n",
    "        plt.close()\n",
    "        \n",
    "    report.save(fname=report_out, open_browser=False, overwrite=True)   \n",
    "    return cluster_stats \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import (\n",
    "    tfr_array_morlet,\n",
    ")\n",
    "\n",
    "# Takes the epochs as input and returns the power time course within given frequencies as an epochs array number of epochs x number of channels x times\n",
    "def get_power_epochs(epochs, power_freq_low_bound, power_freq_high_bound):\n",
    "    frequencies = np.arange(power_freq_low_bound, power_freq_high_bound)  \n",
    "    cycles_per_freq = 6\n",
    "    \n",
    "    power = tfr_array_morlet(epochs.get_data(), freqs=frequencies, n_cycles=cycles_per_freq, output=\"power\", sfreq=config.resample_sfreq)\n",
    "    power_timecourse = np.mean(power, axis=2)\n",
    "\n",
    "    # Transform to epochs and keep metadata\n",
    "    epochs_power_timecourse = mne.EpochsArray(power_timecourse, info=epochs.info)\n",
    "    epochs_power_timecourse.metadata = epochs.metadata\n",
    "\n",
    "    return epochs_power_timecourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis on all the epochs for the beta time course on all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 1 columns\n",
      "1549 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gautier\\AppData\\Local\\Temp/ipykernel_14912/3934033295.py:10: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  power = tfr_array_morlet(epochs.get_data(), freqs=frequencies, n_cycles=cycles_per_freq, output=\"power\", sfreq=config.resample_sfreq)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:   12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1549 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 1 columns\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gautier\\AppData\\Local\\Temp/ipykernel_14912/3731481473.py:12: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  epochs_data = epochs.get_data().transpose(0, 2, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a threshold of 1.961498\n",
      "stat_fun(H1): min=-63.425993 max=27.755327\n",
      "Running initial clustering …\n",
      "Found 2 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Permuting : 499/499 [03:58<00:00,    2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002 0.002]\n",
      "2 sign. clusters\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "Overwriting existing file.\n",
      "Saving report to : C:\\Users\\gautier\\OneDrive - CentraleSupelec\\3A - Master CNN\\Supervised Project\\pipeline project v0\\reports\\cluster_analysis\\start_prod\\beta_cluster_analysis_all_subjects.html\n"
     ]
    }
   ],
   "source": [
    "from mne.report import Report\n",
    "\n",
    "epochs_list = []\n",
    "for subject in config.preprocessed_subjects_list[:2]:\n",
    "    for condition in config.conditions:\n",
    "        epochs = preprocessing.load_subject_epochs_by_type_and_condition(subject, condition, epochs_type, baseline_duration, epoch_duration, pick_type, verbose=False)\n",
    "        epochs = preprocessing.change_bad_channels(epochs)\n",
    "        epochs_list.append(epochs)\n",
    "\n",
    "low_freq = 15\n",
    "high_freq = 30\n",
    "all_epochs = mne.concatenate_epochs(epochs_list)\n",
    "power_epochs = get_power_epochs(all_epochs, low_freq, high_freq)\n",
    "\n",
    "report_out  = cluster_analysis_report_dir + f'beta_cluster_analysis_all_subjects.html'\n",
    "os.makedirs(cluster_analysis_report_dir, exist_ok=True)\n",
    "report      = Report(report_out, verbose=False)\n",
    "\n",
    "power_epochs.pick_types(eeg=True)\n",
    "\n",
    "cluster_stats = compute_and_plot_stca(power_epochs, report, report_out, n_perm=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel names of cluster 1\n",
      "There are 24 channels in the cluster:\n",
      "['Fp1', 'Fp2', 'F7', 'FC5', 'M2', 'P7', 'P3', 'P4', 'P8', 'POz', 'O1', 'O2', 'AF8', 'P5', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT8', 'TP8', 'PO7', 'PO8', 'Oz']\n",
      "channel names of cluster 2\n",
      "There are 24 channels in the cluster:\n",
      "['Fpz', 'F3', 'Fz', 'F4', 'FC5', 'FC1', 'FC2', 'FC6', 'C4', 'CP5', 'CP1', 'CP6', 'P3', 'AF4', 'F1', 'F2', 'FCz', 'C5', 'C1', 'C2', 'C6', 'CP3', 'P1', 'P2']\n"
     ]
    }
   ],
   "source": [
    "print(\"channel names of cluster 1\")\n",
    "mask = cluster_stats[1][0][1]\n",
    "channels = [ch for i, ch in enumerate(power_epochs.info[\"ch_names\"]) if i in mask]\n",
    "print(\"There are \" + str(len(channels)) + \" channels in the cluster:\")\n",
    "print(channels)\n",
    "\n",
    "print(\"channel names of cluster 2\")\n",
    "mask = cluster_stats[1][1][1]\n",
    "channels = [ch for i, ch in enumerate(power_epochs.info[\"ch_names\"]) if i in mask]\n",
    "print(\"There are \" + str(len(channels)) + \" channels in the cluster:\")\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster analysis on the beta time course on the difference between long and short duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mne.viz import plot_compare_evokeds\n",
    "from mne.channels import find_ch_adjacency\n",
    "from mne.stats import spatio_temporal_cluster_test\n",
    "\n",
    "\n",
    "def compute_and_plot_stca_2_conditions(epochs1, epochs2, report, report_out, p_accept = 0.05, n_perm = 1024):\n",
    "\n",
    "    # Running the spatio temporal cluster analysis\n",
    "\n",
    "    epochs1.pick_types(eeg=True)\n",
    "    epochs2.pick_types(eeg=True)\n",
    "    adjacency, _ = find_ch_adjacency(epochs1.info, \"eeg\")\n",
    "\n",
    "    X = [\n",
    "        epochs1.get_data(copy=False).transpose(0, 2, 1),\n",
    "        epochs2.get_data(copy=False).transpose(0, 2, 1),\n",
    "    ]\n",
    "\n",
    "    # Computing the combined evoked response\n",
    "    evo = mne.combine_evoked(\n",
    "        [epochs1.average(), epochs2.average()], weights=[1, -1]\n",
    "    )\n",
    "\n",
    "    cluster_stats = spatio_temporal_cluster_test(X,\n",
    "                                                    n_permutations=n_perm, \n",
    "                                                    threshold=None, \n",
    "                                                    n_jobs=-1, \n",
    "                                                    adjacency=adjacency)        \n",
    "    T_obs, clusters, p_values, H0 = cluster_stats\n",
    "    if len(clusters) == 0:\n",
    "        print('No significant clusters found for this predictor')\n",
    "        return\n",
    "\n",
    "    print(p_values)\n",
    "    good_cluster_inds = np.where(p_values < p_accept)[0]\n",
    "    print(str(len(good_cluster_inds)) + ' sign. clusters')\n",
    "\n",
    "    p_min = np.min(p_values)\n",
    "\n",
    "    #======================================================\n",
    "    # Display clusters information\n",
    "    \n",
    "    #======================================================\n",
    "    # if no cluster, display the lowest p of n.s. cluster (as sanity check)\n",
    "    #======================================================\n",
    "    if len(good_cluster_inds) == 0:\n",
    "        good_cluster_inds = np.where(p_values < p_min+0.01)[0]\n",
    "        print(str(len(good_cluster_inds)) + ' n.s. cluster min p')\n",
    "\n",
    "    #======================================================\n",
    "    #% loop over clusters, plot and save in report\n",
    "    for i_clu, clu_idx in enumerate(good_cluster_inds):\n",
    "        \n",
    "        # unpack cluster information, get unique indices\n",
    "        time_inds, space_inds = np.squeeze(clusters[clu_idx])\n",
    "        ch_inds     = np.unique(space_inds)\n",
    "        time_inds   = np.unique(time_inds)\n",
    "    \n",
    "        # get topography for F stat\n",
    "        f_map = T_obs[time_inds, ...].mean(axis=0)\n",
    "    \n",
    "        # get signals at the sensors contributing to the cluster\n",
    "        # sig_times = blah.times[time_inds]\n",
    "        sig_times = evo.times[time_inds]\n",
    "        \n",
    "        # create spatial mask\n",
    "        mask = np.zeros((f_map.shape[0], 1), dtype=bool)\n",
    "        mask[ch_inds, :] = True\n",
    "    \n",
    "        # initialize figure\n",
    "        fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    \n",
    "        # plot average test statistic and mark significant sensors\n",
    "        f_evoked = mne.EvokedArray(f_map[:, np.newaxis], epochs1.info, tmin=0)\n",
    "        \n",
    "        f_evoked.plot_topomap(times=0, mask=mask, axes=ax_topo, cmap='Greys',\n",
    "                            show=False,\n",
    "                            colorbar=False, mask_params=dict(markersize=10))\n",
    "        image = ax_topo.images[0]\n",
    "        \n",
    "        # create additional axes\n",
    "        divider = make_axes_locatable(ax_topo)\n",
    "    \n",
    "        # add axes for colorbar\n",
    "        ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        plt.colorbar(image, cax=ax_colorbar)\n",
    "        ax_topo.set_xlabel(\n",
    "            'Averaged F-map ({:0.3f} - {:0.3f} s)'.format(*sig_times[[0, -1]]))\n",
    "    \n",
    "        # add new axis for time courses and plot time courses\n",
    "        ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n",
    "        \n",
    "        title = 'Cluster #{0}, {1} sensor, p min value {2}'.format(i_clu + 1, len(ch_inds), p_min)\n",
    "        \n",
    "        plot_compare_evokeds([evo], ci = True, title=title, \n",
    "                            picks=ch_inds, axes=ax_signals,\n",
    "                            legend = 'upper right', split_legend=True, \n",
    "                            truncate_yaxis='auto')\n",
    "    \n",
    "        # plot temporal cluster extent\n",
    "        ymin, ymax = ax_signals.get_ylim()\n",
    "        ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n",
    "                                color='grey', alpha=0.3)\n",
    "    \n",
    "        # clean up viz\n",
    "        fig.subplots_adjust(bottom=.05)\n",
    "\n",
    "        report.add_figure(fig, title=('sign cluster_' + str(p_min)))\n",
    "        plt.close()\n",
    "        \n",
    "        report.save(fname=report_out, open_browser=False, overwrite=True)    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 63\n",
      "Using a threshold of 3.854299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gautier\\AppData\\Local\\Temp/ipykernel_20016/1277441031.py:25: RuntimeWarning: Ignoring argument \"tail\", performing 1-tailed F-test\n",
      "  cluster_stats = spatio_temporal_cluster_test(X,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat_fun(H1): min=0.000000 max=14.480224\n",
      "Running initial clustering …\n",
      "Found 63 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Permuting : 99/99 [00:26<00:00,    3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   1.   1.   0.99 1.   1.   0.87 1.   1.   0.99 1.   1.   1.\n",
      " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      " 1.   1.   0.17 1.   1.   1.   1.  ]\n",
      "0 sign. clusters\n",
      "1 n.s. cluster min p\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving report to : C:\\Users\\gautier\\OneDrive - CentraleSupelec\\3A - Master CNN\\Supervised Project\\pipeline project v0\\reports\\cluster_analysis\\start_prod\\beta_conditions_test.html\n"
     ]
    }
   ],
   "source": [
    "from mne.report import Report\n",
    "\n",
    "# Retrieve the power epochs of long duration and short duration apart\n",
    "\n",
    "low_freq = 15\n",
    "high_freq = 30\n",
    "\n",
    "epochs_lists = {\"L\":[], \"S\":[]}\n",
    "# extract all pairs of condition where one ends up with an L and the other with an S\n",
    "duration_conditions = [conditions for conditions in config.condition_pairs if conditions[0][-1] == \"S\" and conditions[1][-1] == \"L\" or conditions[0][-1] == \"L\" and conditions[1][-1] == \"S\"]\n",
    "\n",
    "# order the tuples so that the first condition is always the one ending up with an L\n",
    "duration_conditions = [conditions if conditions[0][-1] == \"L\" else (conditions[1], conditions[0]) for conditions in duration_conditions]\n",
    "\n",
    "print(duration_conditions)\n",
    "\n",
    "for subject in config.preprocessed_subjects_list:\n",
    "    for conditions in duration_conditions:\n",
    "        epochs_long = preprocessing.load_subject_epochs_by_type_and_condition(subject, conditions[0], epochs_type, baseline_duration, epoch_duration, pick_type, verbose=False)\n",
    "        epochs_lists[\"L\"].append(epochs_long)\n",
    "\n",
    "        epochs_short = preprocessing.load_subject_epochs_by_type_and_condition(subject, conditions[1], epochs_type, baseline_duration, epoch_duration, pick_type, verbose=False)\n",
    "        epochs_lists[\"S\"].append(epochs_short)\n",
    "\n",
    "all_short_epochs = mne.concatenate_epochs(epochs_lists[\"S\"])\n",
    "all_long_epochs = mne.concatenate_epochs(epochs_lists[\"L\"])\n",
    "\n",
    "all_short_power_epochs = get_power_epochs(all_short_epochs, low_freq, high_freq)\n",
    "all_long_power_epochs = get_power_epochs(all_long_epochs, low_freq, high_freq)\n",
    "\n",
    "report_out  = cluster_analysis_report_dir + f'beta_conditions_all_subjects.html'\n",
    "os.makedirs(cluster_analysis_report_dir, exist_ok=True)\n",
    "report      = Report(report_out, verbose=False)\n",
    "\n",
    "compute_and_plot_stca_2_conditions(all_short_power_epochs, all_long_power_epochs,  report, report_out, n_perm=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
